{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 53 is out of bounds for axis 0 with size 50",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ZIYAD\\Desktop\\robotic-warehouse-master\\test2.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ZIYAD/Desktop/robotic-warehouse-master/test2.ipynb#W0sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m reward \u001b[39m=\u001b[39m get_reward(state, action, next_state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ZIYAD/Desktop/robotic-warehouse-master/test2.ipynb#W0sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Update the Q-table\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ZIYAD/Desktop/robotic-warehouse-master/test2.ipynb#W0sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m Q \u001b[39m=\u001b[39m update_Q(state, action, next_state, reward, Q, alpha, gamma)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ZIYAD/Desktop/robotic-warehouse-master/test2.ipynb#W0sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# Update the state and action\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ZIYAD/Desktop/robotic-warehouse-master/test2.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mif\u001b[39;00m reward \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m100\u001b[39m:\n",
      "\u001b[1;32mc:\\Users\\ZIYAD\\Desktop\\robotic-warehouse-master\\test2.ipynb Cell 1\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ZIYAD/Desktop/robotic-warehouse-master/test2.ipynb#W0sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_Q\u001b[39m(state, action, next_state, reward, Q, alpha, gamma):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ZIYAD/Desktop/robotic-warehouse-master/test2.ipynb#W0sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     max_Q \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(Q[next_state, :])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ZIYAD/Desktop/robotic-warehouse-master/test2.ipynb#W0sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     Q[state, action] \u001b[39m=\u001b[39m Q[state, action] \u001b[39m+\u001b[39m alpha \u001b[39m*\u001b[39m (reward \u001b[39m+\u001b[39m gamma \u001b[39m*\u001b[39m max_Q \u001b[39m-\u001b[39m Q[state, action])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ZIYAD/Desktop/robotic-warehouse-master/test2.ipynb#W0sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Q\n",
      "\u001b[1;31mIndexError\u001b[0m: index 53 is out of bounds for axis 0 with size 50"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the number of states and actions\n",
    "x=5\n",
    "y=10\n",
    "num_states = x*y\n",
    "num_actions = 5\n",
    "#5 actions: up, down, left, right, stay\n",
    "def up(state):\n",
    "    return state - y\n",
    "def down(state):\n",
    "    return state + y\n",
    "def left(state):\n",
    "    return state - 1\n",
    "def right(state):\n",
    "    return state + 1\n",
    "def stay(state):\n",
    "    return state\n",
    "\n",
    "# Initialize the Q-table\n",
    "Q = np.zeros((num_states, num_actions))\n",
    "\n",
    "# Define the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Define the reward function\n",
    "def get_reward(state, action, next_state):\n",
    "    # If the robot reaches the exit, return a large positive reward\n",
    "    if next_state == 49:\n",
    "        return 100\n",
    "    # If the robot hits an obstacle, return a negative reward\n",
    "    if next_state in [2, 3, 5, 9, 15, 20, 21, 26, 45, 46, 47, 48]:\n",
    "        return -100\n",
    "    if next_state >= 50 or next_state < 0:\n",
    "        return -100\n",
    "    # Otherwise, return a small positive reward\n",
    "    return 1\n",
    "\n",
    "# Define the update rule for the Q-table\n",
    "def update_Q(state, action, next_state, reward, Q, alpha, gamma):\n",
    "    max_Q = max(Q[next_state, :])\n",
    "    Q[state, action] = Q[state, action] + alpha * (reward + gamma * max_Q - Q[state, action])\n",
    "    return Q\n",
    "\n",
    "# Start the training loop\n",
    "for i in range(10000):\n",
    "    # Initialize the state and action\n",
    "    state = 0\n",
    "    action = np.argmax(Q[state, :] + np.random.randn(1, num_actions) * (1. / (i + 1)))\n",
    "    while state != 49:\n",
    "        # Take the action and observe the next state and reward\n",
    "        if action == 0:\n",
    "            next_state = up(state)\n",
    "        elif action == 1:\n",
    "            next_state = down(state)\n",
    "        elif action == 2:\n",
    "            next_state = left(state)\n",
    "        elif action == 3:\n",
    "            next_state = right(state)\n",
    "        else:\n",
    "            next_state = stay(state)\n",
    "        \n",
    "        reward = get_reward(state, action, next_state)\n",
    "\n",
    "        # Update the Q-table\n",
    "        Q = update_Q(state, action, next_state, reward, Q, alpha, gamma)\n",
    "        # Update the state and action\n",
    "        if reward != -100:\n",
    "            state = next_state\n",
    "        action = np.argmax(Q[state, :] + np.random.randn(1, num_actions) * (1. / (i + 1)))\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 2 3 1 0 2 3 2 0 2 2 0 2 2 0 1 3 3 1 1 2 0 2 1 1 3 1 3 2 2 3 1 2 3 2 3\n",
      " 1 2 2 3 2 2 3 1 2 3 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#based on table Q, get best action for each state\n",
    "best_action = np.argmax(Q, axis=1)\n",
    "print(best_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  91.   0.   0.1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Q[47, :])\n",
    "np.argmax(Q[47, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10.       ,  -8.9332489,  -8.9332489,  -8.9332489])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q[4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Q[state, :] + np.random.randn(1, num_actions) * (1. / (i + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 30, 31, 32, 33, 34, 35, 6, 12, 18, 24, 11, 17, 23, 29, 36, 20, 21]\n",
      "23\n",
      "[7, 8, 9, 10, 13, 14, 15, 16, 19, 22, 25, 26, 27, 28]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Define the number of states and actions\n",
    "x=6\n",
    "y=6\n",
    "borders=[i for i in range(0,x)]+[i for i in range(x*(y-1),x*y)]+[i*x for i in range(1,y-1)]+[(i+1)*x-1 for i in range(1,y-1)]\n",
    "borders.append(x*y)\n",
    "borders=borders+[20,21]\n",
    "print(borders)\n",
    "print(len( borders))\n",
    "\n",
    "\n",
    "#list from 0 to 35\n",
    "all= [i for i in range(x*y+1)]\n",
    "#list of all states not in borders\n",
    "states = [i for i in all if i not in borders]\n",
    "print(states)\n",
    "\n",
    "num_states = x*y+1\n",
    "num_actions = 4\n",
    "num_robot = 2\n",
    "\n",
    "# Initialize the Q-table\n",
    "Q=[]\n",
    "for i in range(num_robot):\n",
    "    Q.append(np.zeros((num_states, num_actions)))\n",
    "\n",
    "# Define the learning rate and discount factor\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "\n",
    "# Define the reward function\n",
    "def get_reward(state, action, next_state,target=28):\n",
    "\n",
    "    # If the robot hits an obstacle, return a negative reward\n",
    "    if next_state in borders:\n",
    "        return -100\n",
    "    # If the robot reaches the exit, return a large positive reward\n",
    "    if next_state == target:\n",
    "        return 100\n",
    "    \n",
    "    # Otherwise, return a small positive reward\n",
    "    return -1\n",
    "\n",
    "# Define the update rule for the Q-table\n",
    "def update_Q(state, action, next_state, reward, Q, alpha, gamma):\n",
    "    max_Q = max(Q[next_state, :])\n",
    "    Q[state, action] = Q[state, action] + alpha * (reward + gamma * max_Q - Q[state, action])\n",
    "    return Q\n",
    "\n",
    "\n",
    "r1=0\n",
    "r2=0\n",
    "# Start the training loop\n",
    "for i in range(10000):\n",
    "    # Initialize the state and action\n",
    "    #random start state not in borders\n",
    "\n",
    "\n",
    "    state1 = random.randint(0,len(states)-1)\n",
    "    state1=states[state1]\n",
    "    states2=states.copy()\n",
    "    states2.remove(state1)\n",
    "    state2 = random.randint(0,len(states)-1)\n",
    "    state2=states[state2]\n",
    "\n",
    "    \n",
    "\n",
    "    action1 = np.argmax(Q[0][state1, :] + np.random.randn(1, num_actions) * (1. / (i + 1)))\n",
    "    action2 = np.argmax(Q[1][state2, :] + np.random.randn(1, num_actions) * (1. / (i + 1)))\n",
    "\n",
    "    target = 28\n",
    "    while state1 != target and state2 != target:\n",
    "        # Take the action and observe the next state and reward\n",
    "        if action1 == 0:#go up\n",
    "            next_state1 = state1 - y\n",
    "        elif action1 == 1:#go down\n",
    "            next_state1 = state1 + y\n",
    "        elif action1 == 2:#go left\n",
    "            next_state1 = state1 - 1\n",
    "        elif action1 == 3:#go right\n",
    "            next_state1 = state1 + 1\n",
    "        if next_state1 == state2:#if robot 1 and 2 collide\n",
    "                next_state1 = x*y\n",
    "\n",
    "        reward1 = get_reward(state1, action1, next_state1)\n",
    "        Q[0] = update_Q(state1, action1, next_state1, reward1, Q[0], alpha, gamma)\n",
    "        if reward1 != -100:\n",
    "            state1 = next_state1\n",
    "\n",
    "        action1 = np.argmax(Q[0][state1, :] + np.random.randn(1, num_actions) * (1. / (i + 1)))\n",
    "\n",
    "\n",
    "        if action2 == 0:\n",
    "            next_state2 = state2 - y\n",
    "        elif action2 == 1:\n",
    "            next_state2 = state2 + y\n",
    "        elif action2 == 2:\n",
    "            next_state2 = state2 - 1\n",
    "        elif action2 == 3:\n",
    "            next_state2 = state2 + 1\n",
    "        if next_state2 == state1:\n",
    "                next_state2 = x*y\n",
    "        \n",
    "\n",
    "        \n",
    "        reward2 = get_reward(state2, action2, next_state2)\n",
    "        # Update the Q-table\n",
    "        \n",
    "        Q[1] = update_Q(state2, action2, next_state2, reward2, Q[1], alpha, gamma)\n",
    "        # Update the state and action\n",
    "        \n",
    "        if reward2 != -100:\n",
    "            state2 = next_state2\n",
    "        \n",
    "        action2 = np.argmax(Q[1][state2, :] + np.random.randn(1, num_actions) * (1. / (i + 1)))\n",
    "\n",
    "    if state1 == target:\n",
    "        r1+=1\n",
    "    elif state2 == target:\n",
    "        r2+=1\n",
    "#print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-19.         -20.14307497 -19.          39.79315702]\n",
      " [-10.         -10.          -6.88708477  47.21374331]\n",
      " [-19.         -10.252      -15.13397125  57.47957139]\n",
      " [-27.1         69.95204566 -19.19591621 -27.1       ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-19.12210252  44.66031399 -19.         -20.76164254]\n",
      " [-13.7464174  -19.           1.38715894 -19.36643461]\n",
      " [ -0.75887265 -10.          -0.4864771   59.51838693]\n",
      " [ -0.72626811  88.93608036  -0.2319751  -10.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [ -0.19        56.38014932 -10.         -10.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.         100.           0.         -10.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [-10.09       -10.         -10.          69.58684222]\n",
      " [-10.         -10.          -0.2071      88.8515339 ]\n",
      " [  0.           0.           0.         100.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Q[0])#robot 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8, 9, 10, 16, 22, 28]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_path(Q, state, target):\n",
    "    path = [state]\n",
    "    while state != target:\n",
    "        action = np.argmax(Q[state, :])\n",
    "        if action == 0:\n",
    "            state = state - y\n",
    "        elif action == 1:\n",
    "            state = state + y\n",
    "        elif action == 2:\n",
    "            state = state - 1\n",
    "        elif action == 3:\n",
    "            state = state + 1\n",
    "        path.append(state)\n",
    "    return path\n",
    "get_path(Q[0], 7, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 15, 16, 22, 28]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_path(Q[1], 14, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56877\n",
      "43123\n"
     ]
    }
   ],
   "source": [
    "print(r1)\n",
    "print(r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
